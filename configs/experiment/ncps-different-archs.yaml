# @package _global_
defaults:
  - override /model: gcn-graphconv-ensemble
  - override /trainer: n-cps

trainer:
  init:
    optimizer:
      # GCN optimizer
      - _target_: torch.optim.AdamW
        _partial_: true
        lr: 0.01
        weight_decay: 0.01
      # GraphConv optimizer
      - _target_: torch.optim.AdamW
        _partial_: true
        lr: 0.01
        weight_decay: 0.005
    scheduler:
      # GCN scheduler
      - _target_: torch.optim.lr_scheduler.StepLR
        _partial_: true
        step_size: 10
        gamma: 0.9
      # GraphConv scheduler
      - _target_: torch.optim.lr_scheduler.StepLR
        _partial_: true
        step_size: 1
        gamma: 0.975
    cps_loss_weight: 1.97  # for num_models=3
    # cps_loss_weight: 1.72  # for num_models=2
