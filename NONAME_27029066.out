ERROR: Unable to locate a modulefile for 'python/3.10.12'
Loaded module: cuda/12.1
================================
Job ID: 
Node: 
Start time: Sat Nov 15 09:29:51 CET 2025
================================
wandb: Currently logged in as: adopetr (adopetr-danmarks-tekniske-universitet-dtu) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run qvuffauk
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in ./logs/wandb/run-20251115_093012-qvuffauk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gcn_seed=0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/adopetr-danmarks-tekniske-universitet-dtu/semi-supervised-ensembles
wandb: üöÄ View run at https://wandb.ai/adopetr-danmarks-tekniske-universitet-dtu/semi-supervised-ensembles/runs/qvuffauk
/zhome/f9/1/147385/my_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
dataset:
  dataset_name: qm9
  num_outputs: 1
  init:
    _target_: qm9.QM9DataModule
    data_augmentation: false
    name: qm9
    target: 2
    data_dir: ./data
    batch_size_train: 100
    batch_size_inference: 2048
    num_workers: 4
    splits:
    - 0.72
    - 0.08
    - 0.1
    - 0.1
    seed: 0
    subset_size: null
trainer:
  method: semi-supervised-ensemble
  train:
    total_epochs: 250
    validation_interval: 10
  init:
    _target_: trainer.SemiSupervisedEnsemble
    supervised_criterion:
      _target_: torch.nn.MSELoss
    optimizer:
      _target_: torch.optim.AdamW
      _partial_: true
      lr: 0.0003
      weight_decay: 0.0001
    scheduler:
      _target_: torch.optim.lr_scheduler.StepLR
      _partial_: true
      step_size: 10
      gamma: 0.9
logger:
  _target_: logger.WandBLogger
  group: ${dataset.dataset_name}
  name: ${model.name}_seed=${seed}
  job_type: test
  entity: adopetr-danmarks-tekniske-universitet-dtu
  project_name: semi-supervised-ensembles
  disable: false
  local_dir: ./logs
model:
  name: gcn
  init:
    _target_: models.GCN
    _partial_: false
    num_node_features: 11
seed: 0
device: unset
force_deterministic: false
debug_mode: false
result_dir: ./results
compile_model: false

QM9 dataset loaded with 10466 labeled, 94198 unlabeled, 13083 validation, and 13084 test samples.
Batch sizes: labeled=100, unlabeled=100
  0%|          | 0/250 [00:00<?, ?it/s]/zhome/f9/1/147385/my_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
  warnings.warn(warn_msg)
/zhome/f9/1/147385/.lsbatch/1763195390.27029066.shell: line 34: 136926 Killed                  python src/run.py "$@"
================================
End time: Sat Nov 15 09:30:36 CET 2025
Job finished!
================================
Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7fa7984bbe20>
Traceback (most recent call last):
  File "/appl9/python/3.10.13/lib/python3.10/_weakrefset.py", line 39, in _remove
Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7fa7984bbe20>
Traceback (most recent call last):
  File "/appl9/python/3.10.13/lib/python3.10/_weakrefset.py", line 39, in _remove
    def _remove(item, selfref=ref(self)):
KeyboardInterrupt: 
    def _remove(item, selfref=ref(self)):
KeyboardInterrupt: 
Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x7fa7984bbe20>
Traceback (most recent call last):
  File "/appl9/python/3.10.13/lib/python3.10/_weakrefset.py", line 39, in _remove
    def _remove(item, selfref=ref(self)):
KeyboardInterrupt: 
Traceback (most recent call last):
  File "/appl9/python/3.10.13/lib/python3.10/multiprocessing/resource_sharer.py", line 138, in _serve
    with self._listener.accept() as conn:
  File "/appl9/python/3.10.13/lib/python3.10/multiprocessing/connection.py", line 465, in accept
    deliver_challenge(c, self._authkey)
  File "/appl9/python/3.10.13/lib/python3.10/multiprocessing/connection.py", line 738, in deliver_challenge
    connection.send_bytes(CHALLENGE + message)
  File "/appl9/python/3.10.13/lib/python3.10/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/appl9/python/3.10.13/lib/python3.10/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/appl9/python/3.10.13/lib/python3.10/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27029066: <NONAME> in cluster <dcc> Exited

Job <NONAME> was submitted from host <n-62-9-41> by user <s194778> in cluster <dcc> at Sat Nov 15 09:29:50 2025
Job was executed on host(s) <n-62-11-61>, in queue <hpc>, as user <s194778> in cluster <dcc> at Sat Nov 15 09:29:51 2025
</zhome/f9/1/147385> was used as the home directory.
</zhome/f9/1/147385/02456-g82-dl-project> was used as the working directory.
Started at Sat Nov 15 09:29:51 2025
Terminated at Sat Nov 15 09:30:45 2025
Results reported at Sat Nov 15 09:30:45 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
#SBATCH --job-name=gnn_qm9
#SBATCH --output=logs/output_%j.log
#SBATCH --error=logs/error_%j.log
#SBATCH --time=24:00:00
#SBATCH --mem=32G
#SBATCH --cpus-per-task=4
#SBATCH --gres=gpu:1
#SBATCH --partition=gpu  # Adjust for your HPC

# Load required modules (adjust for your HPC system)
module purge
module load python/3.10.12
module load cuda/12.1

# Activate virtual environment
source ~/my_venv/bin/activate

# Set WandB mode (use offline if compute nodes don't have internet)
# export WANDB_MODE=offline
# export WANDB_DIR=$HOME/wandb_logs

# Change to project directory
cd ~/02456-g82-dl-project/

# Print configuration info
echo "================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_NODELIST"
echo "Start time: $(date)"
echo "================================"

# Run experiment with any command-line arguments
python src/run.py "$@"

echo "================================"
echo "End time: $(date)"
echo "Job finished!"
echo "================================"

# Sync WandB logs if using offline mode
# wandb sync $WANDB_DIR/wandb/offline-run-*

------------------------------------------------------------

TERM_MEMLIMIT: job killed after reaching LSF memory usage limit.
Exited with signal termination: 25.

Resource usage summary:

    CPU time :                                   18.00 sec.
    Max Memory :                                 1024 MB
    Average Memory :                             740.67 MB
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                21
    Run time :                                   64 sec.
    Turnaround time :                            55 sec.

The output (if any) is above this job summary.

